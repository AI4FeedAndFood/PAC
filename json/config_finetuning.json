{
    "model_config": {
        "base_model": "/content/drive/MyDrive/Baptiste/model_estimates/model13", 
        "new_model" : false, 
        "save_model_path": "/content/",
        "save_on_dick" : true,
        "push_on_hub": false,
        "finetuned_model":"Baprick/llama3_ocr_value_0.2.2", 
        "max_seq_length": 8192, 
        "dtype":null,
        "load_in_4bit": true
    },
    "datasets" : {
        "dataset_train_on_disk" : true,
        "dataset_train_name" : "/content/drive/MyDrive/Baptiste/Data/metaset1.1",
        "split_train" : "train",
        "dataset_test_on_disk" : true,
        "dataset_test_name" : "/content/drive/MyDrive/Baptiste/Data/metaset1.1",
        "input_field": "prompt",
        "split_test" : "test"
    },
    "lora_config": {
      "r": 8,
      "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj"],
      "lora_alpha":8, 
      "lora_dropout":0, 
      "bias":"None",
      "use_gradient_checkpointing":true, 
      "use_rslora":false,
      "use_dora":false, 
      "loftq_config":null 
    },
    "training_config": {
        "per_device_train_batch_size": 1, 
        "gradient_accumulation_steps": 4, 
        "warmup_steps": 5,
        "max_steps":0, 
        "num_train_epochs": 1,
        "learning_rate": 2e-4, 
        "logging_steps": 1, 
        "optim" :"adamw_8bit", 
        "weight_decay" : 0.01,  
        "lr_scheduler_type": "linear",
        "seed" : 42, 
        "output_dir" : "outputs"
    }
}
